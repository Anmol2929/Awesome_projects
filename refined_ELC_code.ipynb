{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import fftpack\n",
    "from scipy import ndimage\n",
    "from sklearn import svm, metrics\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import imageio\n",
    "import matplotlib.image as mpimage\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "import datetime as dt\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"/home/csed/ELC_activity/train\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ada', 'haha', 'idi', 'sasa', 'uda']\n"
     ]
    }
   ],
   "source": [
    "train_labels=os.listdir(train_path)\n",
    "\n",
    "train_labels.sort()\n",
    "\n",
    "print(train_labels)\n",
    "nb_classes= 5\n",
    "global_features_train=[]\n",
    "train_classes=[]\n",
    "\n",
    "\n",
    "\n",
    "i,j=0,0\n",
    "k=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[status] processed folder: ada\n",
      "[status] processed folder: haha\n",
      "[status] processed folder: idi\n",
      "[status] processed folder: sasa\n",
      "[status] processed folder: uda\n",
      "[status] completed global feature extraction..\n",
      "[status] feature vector size (493, 32, 32, 4)\n",
      "[status] training labels (493,)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.pyplot import imread\n",
    "for training_name in train_labels:\n",
    "    path=os.path.join(train_path,training_name,'*')\n",
    "    files=glob.glob(path)\n",
    "    current_label=training_name\n",
    "    k=1\n",
    "    for fl in files:\n",
    "        image=imread(fl)\n",
    "        global_feature=np.hstack([image])\n",
    "        train_classes.append(current_label)\n",
    "        global_features_train.append(global_feature)\n",
    "\n",
    "        i+=1\n",
    "        k+1\n",
    "    print(\"[status] processed folder: {}\".format(current_label))\n",
    "    j+=1\n",
    "print(\"[status] completed global feature extraction..\")\n",
    "print(\"[status] feature vector size {}\".format(np.array(global_features_train).shape))\n",
    "print(\"[status] training labels {}\".format(np.array(train_classes).shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[status] training labels encoded...\n"
     ]
    }
   ],
   "source": [
    "#labels = (np.arange(nb_classes) == labels[:,None]).astype(np.float32)\n",
    "targetNames=np.unique(train_classes)\n",
    "le=LabelEncoder()\n",
    "target=le.fit_transform(train_classes)\n",
    "print(\"[status] training labels encoded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, nx, ny,ch=np.array(global_features_train).shape\n",
    "d2_global_features=np.array(global_features_train).reshape((n_samples, nx*ny*ch))\n",
    "#scaler=MinMaxScaler(feature_range=(0,1))\n",
    "#rescaled_features=scaler.fit_transform(d2_global_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Status] feature vector normalized...\n",
      "[Status] target label[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "[Status] target label shape (493,)\n"
     ]
    }
   ],
   "source": [
    "print(\"[Status] feature vector normalized...\")\n",
    "\n",
    "print(\"[Status] target label{}\".format(target))\n",
    "print(\"[Status] target label shape {}\".format(target.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"dataset_1\": shape (493,), type \"<i8\">"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5f_data=h5py.File('/home/csed/ELC_activity/output_train_svm/dataelc.h5','w')\n",
    "h5f_data.create_dataset('dataset_1',data=np.array(d2_global_features))\n",
    "\n",
    "h5f_label=h5py.File('/home/csed/ELC_activity/output_train_svm/labelselc.h5','w')\n",
    "h5f_label.create_dataset('dataset_1',data=np.array(target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f_data.close()\n",
    "h5f_label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f_data=h5py.File('/home/csed/ELC_activity/output_train_svm/dataelc.h5','r')\n",
    "h5f_label=h5py.File('/home/csed/ELC_activity/output_train_svm/labelselc.h5','r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_features_string_train= h5f_data['dataset_1']\n",
    "global_labels_string_train=h5f_label['dataset_1']\n",
    "global_features_train=np.array(global_features_string_train)\n",
    "global_labels_train=np.array(global_labels_string_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f_data.close()\n",
    "h5f_label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Status] training feature shape: (493, 4096)\n",
      "[Status] labels shape: (493,)\n"
     ]
    }
   ],
   "source": [
    "print(\"[Status] training feature shape: {}\".format(global_features_train.shape))\n",
    "\n",
    "print(\"[Status] labels shape: {}\".format(global_labels_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=4, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf,global_features_train,global_labels_train , scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.992 (0.006)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(clf, global_features_train,global_labels_train , cv=10)\n",
    "conf_mat = confusion_matrix(global_labels_train, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[100   0   0   0   0]\n",
      " [  0 100   0   0   0]\n",
      " [  1   0  99   0   0]\n",
      " [  0   0   0  93   0]\n",
      " [  2   0   0   0  98]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n%s\" % conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.988 (0.004)\n",
      "Confusion matrix:\n",
      "[[100   0   0   0   0]\n",
      " [  0 100   0   0   0]\n",
      " [  1   0  99   0   0]\n",
      " [  0   0   0  93   0]\n",
      " [  2   0   0   0  98]]\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=2, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(clf,global_features_train,global_labels_train , scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "y_pred = cross_val_predict(clf, global_features_train,global_labels_train , cv=10)\n",
    "conf_mat = confusion_matrix(global_labels_train, y_pred)\n",
    "print(\"Confusion matrix:\\n%s\" % conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
